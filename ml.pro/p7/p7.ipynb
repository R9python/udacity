{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习进阶（S13）毕业项目 - 猫狗大战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目：识别图片中是猫还是狗\n",
    "---\n",
    "* 此项目是kaggle平台上的一个比赛项目，最终的要求是提供一个模型来识别图片中的对象是猫还是狗。\n",
    "* 这里会使用深度学习中的卷积神经网络来构建模型。\n",
    "* 最总要求测试评分进入 kaggle Public Leaderboard 前10%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 1: 数据探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog.9220.jpg', 'dog.4153.jpg', 'cat.4113.jpg', 'dog.7547.jpg', 'cat.7459.jpg', 'dog.10028.jpg', 'cat.11954.jpg', 'cat.7368.jpg', 'dog.3505.jpg', 'cat.12057.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 读取训练集\n",
    "train_files = os.listdir('train')\n",
    "print(train_files[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 寻找异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 定义ImageNet中识别猫狗的分类 https://blog.csdn.net/zhangjunbob/article/details/53258524\n",
    "dogs = [\n",
    " 'n02085620','n02085782','n02085936','n02086079','n02086240','n02086646','n02086910','n02087046'\n",
    ",'n02087394','n02088094','n02088238','n02088364','n02088466','n02088632','n02089078','n02089867'\n",
    ",'n02089973','n02090379','n02090622','n02090721','n02091032','n02091134','n02091244','n02091467'\n",
    ",'n02091635','n02091831','n02092002','n02092339','n02093256','n02093428','n02093647','n02093754'\n",
    ",'n02093859','n02093991','n02094114','n02094258','n02094433','n02095314','n02095570','n02095889'\n",
    ",'n02096051','n02096177','n02096294','n02096437','n02096585','n02097047','n02097130','n02097209'\n",
    ",'n02097298','n02097474','n02097658','n02098105','n02098286','n02098413','n02099267','n02099429'\n",
    ",'n02099601','n02099712','n02099849','n02100236','n02100583','n02100735','n02100877','n02101006'\n",
    ",'n02101388','n02101556','n02102040','n02102177','n02102318','n02102480','n02102973','n02104029'\n",
    ",'n02104365','n02105056','n02105162','n02105251','n02105412','n02105505','n02105641','n02105855'\n",
    ",'n02106030','n02106166','n02106382','n02106550','n02106662','n02107142','n02107312','n02107574'\n",
    ",'n02107683','n02107908','n02108000','n02108089','n02108422','n02108551','n02108915','n02109047'\n",
    ",'n02109525','n02109961','n02110063','n02110185','n02110341','n02110627','n02110806','n02110958'\n",
    ",'n02111129','n02111277','n02111500','n02111889','n02112018','n02112137','n02112350','n02112706'\n",
    ",'n02113023','n02113186','n02113624','n02113712','n02113799','n02113978']\n",
    "\n",
    "cats=['n02123045','n02123159','n02123394','n02123597','n02124075','n02125311','n02127052']\n",
    "\n",
    "\n",
    "# 采用InceptionResNetV2预测\n",
    "# 参考 https://keras.io/zh/applications/#applications\n",
    "\n",
    "\n",
    "\n",
    "#存储不能识别为猫狗的异常图片\n",
    "my_unknow_images = []\n",
    "from keras.applications.inception_resnet_v2 import *\n",
    "# # 输入：图片路径\n",
    "# # 输出：预测概率，格式(class, description, probability)\n",
    "# #       例如 [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357)]\n",
    "def my_predict(img_path_list):\n",
    "    model = InceptionResNetV2(weights='imagenet')\n",
    "    for image_path in img_path_list:\n",
    "        img = image.load_img(image_path, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        preds = model.predict(x)\n",
    "        result = decode_predictions(preds, top=10)[0]\n",
    "        if not is_cat_dog(result):\n",
    "            my_unknow_images.append(image_path)\n",
    "\n",
    "# 根据模型预测的结果查看是否属于猫狗的范围\n",
    "def is_cat_dog(preds_result):\n",
    "    my_labels = dogs[:]\n",
    "    my_labels[len(my_labels):len(my_labels)] = cats\n",
    "    a = [x[0] in my_labels for x in preds_result]\n",
    "#     print(sum(a))\n",
    "    return sum(a) > 0        \n",
    "\n",
    "# iscatdog = is_cat_dog([(u'n02504013', u'Indian_elephant', 0.82658225), \n",
    "#                        (u'n01871265', u'tusker', 0.1122357), \n",
    "#                        (u'n02123394', u'test', 0.0000000)])\n",
    "# print(iscatdog)\n",
    "\n",
    "my_predict(['train/cat.0.jpg'])\n",
    "print(my_unknow_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 显示异常图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 16))\n",
    "# plt.title('aaa')\n",
    "# plt.axis('off')\n",
    "# plt.imshow('train/cat.0.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理异常图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把异常图片从train移动到unknown文件夹\n",
    "def move_images_to(files, dest_path):\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.mkdir(dest_path)\n",
    "        \n",
    "    for file in files:\n",
    "        shutil.move(\"t1/\" + file, dest_path)\n",
    "    \n",
    "# files = ['cat.3.jpg','cat.5.jpg']\n",
    "# move_images_to(files, 'unknow')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备训练集，验证集，测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my train data count: 20000 my valid data count: 5000\n",
      "train cat count: 9985\n",
      "train dog count: 10015\n",
      "['cat.1261.jpg', 'cat.7111.jpg', 'cat.6767.jpg', 'cat.2073.jpg', 'cat.9640.jpg', 'cat.6320.jpg', 'cat.3348.jpg', 'cat.10001.jpg', 'cat.9011.jpg', 'cat.1886.jpg']\n",
      "['dog.6268.jpg', 'dog.3490.jpg', 'dog.5809.jpg', 'dog.118.jpg', 'dog.3911.jpg', 'dog.1130.jpg', 'dog.6036.jpg', 'dog.5422.jpg', 'dog.4428.jpg', 'dog.573.jpg']\n",
      "valid cat count: 2515\n",
      "valid dog count: 2485\n",
      "['cat.6557.jpg', 'cat.327.jpg', 'cat.65.jpg', 'cat.243.jpg', 'cat.10629.jpg', 'cat.4179.jpg', 'cat.11125.jpg', 'cat.8824.jpg', 'cat.7439.jpg', 'cat.4687.jpg']\n",
      "['dog.5907.jpg', 'dog.5663.jpg', 'dog.7991.jpg', 'dog.1576.jpg', 'dog.1397.jpg', 'dog.2656.jpg', 'dog.11533.jpg', 'dog.4108.jpg', 'dog.371.jpg', 'dog.8936.jpg']\n"
     ]
    }
   ],
   "source": [
    "from operator import is_not\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_files = os.listdir('train')\n",
    "test_files = os.listdir('test')\n",
    "\n",
    "# 参考 http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "my_train_files, my_valid_files = train_test_split(train_files,test_size=0.2,random_state = 0)\n",
    "print('my train data count:', len(my_train_files), 'my valid data count:', len(my_valid_files))\n",
    "\n",
    "# my train data 细分为cat和dog\n",
    "train_cat_list = [file if file.split('.')[0] == 'cat' else None for file in my_train_files]\n",
    "train_cat_list = list(filter(None.__ne__, train_cat_list))\n",
    "# train_cat_list = filter(partial(is_not, None), train_cat_list)\n",
    "\n",
    "train_dog_list = [file if file.split('.')[0] == 'dog' else None for file in my_train_files]\n",
    "train_dog_list = list(filter(None.__ne__, train_dog_list))\n",
    "# train_dog_list = filter(partial(is_not, None), train_dog_list)\n",
    "\n",
    "print('train cat count:', len(train_cat_list))\n",
    "print('train dog count:', len(train_dog_list))\n",
    "\n",
    "print(train_cat_list[0:10])\n",
    "print(train_dog_list[0:10])\n",
    "\n",
    "# my valid data 细分为cat， dog\n",
    "valid_cat_list = [file if file.split('.')[0] == 'cat' else None for file in my_valid_files]\n",
    "valid_cat_list = list(filter(None.__ne__, valid_cat_list))\n",
    "\n",
    "valid_dog_list = [file if file.split('.')[0] == 'dog' else None for file in my_valid_files]\n",
    "valid_dog_list = list(filter(None.__ne__, valid_dog_list))\n",
    "\n",
    "print('valid cat count:', len(valid_cat_list))\n",
    "print('valid dog count:', len(valid_dog_list))\n",
    "\n",
    "print(valid_cat_list[0:10])\n",
    "print(valid_dog_list[0:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文件目录分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:09<00:00, 180.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5030 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "def my_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "my_mkdir('train_classify')\n",
    "my_mkdir('train_classify/cat')\n",
    "my_mkdir('train_classify/dog')\n",
    "my_mkdir('valid_classify')\n",
    "my_mkdir('valid_classify/cat')\n",
    "my_mkdir('valid_classify/dog')\n",
    "my_mkdir('test_nolabel')\n",
    "\n",
    "# my_mkdir('test_kaggle')\n",
    "# os.symlink('../test/', 'test_kaggle/test')\n",
    "\n",
    "for file in train_cat_list:\n",
    "    os.symlink('../../train/' + file, 'train_classify/cat/' + file)\n",
    "    \n",
    "for file in train_dog_list:\n",
    "    os.symlink('../../train/' + file, 'train_classify/dog/' + file)\n",
    "\n",
    "for file in valid_cat_list:\n",
    "    os.symlink('../../train/' + file, 'valid_classify/cat/' + file)\n",
    "\n",
    "for file in valid_cat_list:\n",
    "    os.symlink('../../train/' + file, 'valid_classify/dog/' + file)\n",
    "    \n",
    "for file in test_files:\n",
    "    os.symlink('../test/' + file, 'test_nolabel/' + file)\n",
    "\n",
    "# 对测试集预处理\n",
    "X_test = []\n",
    "for file in tqdm(test_files):\n",
    "    img = image.load_img('test_nolabel/'+file, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    X_test.append(x)\n",
    "    \n",
    "    \n",
    "gen = ImageDataGenerator() # 参考 https://keras.io/zh/preprocessing/image/#imagedatagenerator\n",
    "train_generator = gen.flow_from_directory(directory=\"train_classify\", \n",
    "                                          target_size=(224, 224), \n",
    "                                          shuffle=False, \n",
    "                                          batch_size=32,\n",
    "                                          class_mode=\"categorical\")\n",
    "\n",
    "valid_generator = gen.flow_from_directory(directory='valid_classify',\n",
    "                                               target_size=(224, 224),\n",
    "                                               shuffle=False, \n",
    "                                               batch_size=32,\n",
    "                                               class_mode='categorical')\n",
    "\n",
    "test_generator = gen.flow_from_directory(directory=\"test_nolabel\",\n",
    "                                         target_size=(224, 224), \n",
    "                                         shuffle=False, \n",
    "                                         batch_size=32, \n",
    "                                         class_mode=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 2: 模型探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet50探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-418f08f3b505>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 构建不带分类器的预训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 添加全局平均池化层\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "# 构建不带分类器的预训练模型\n",
    "base_model = ResNet50(input_tensor=Input((224, 224, 3)), weights='imagenet', include_top=False)\n",
    "# 添加全局平均池化层\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "# 添加Dropout\n",
    "x = Dropout(0.5)(x)\n",
    "# 添加一个分类器\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "# 构建我们需要训练的完整模型\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# 编译模型\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)\n",
    "# X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "#训练模型并保存具有最佳验证loss的模型权重\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.ResNet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs=5,\n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2cb618815a27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 加载具有最佳验证loss的模型权重\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models/weights.best.ResNet50.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 将每个预测值限制到了 [0.005, 0.995] 个区间内，这个原因很简单，kaggle 官方的评估标准是 LogLoss，\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 加载具有最佳验证loss的模型权重\n",
    "model.load_weights('saved_models/weights.best.ResNet50.hdf5')\n",
    "\n",
    "y_pred = model.predict(X_test, verbose=1)\n",
    "# 将每个预测值限制到了 [0.005, 0.995] 个区间内，这个原因很简单，kaggle 官方的评估标准是 LogLoss，\n",
    "# 对于预测正确的样本，0.995 和 1 相差无几，但是对于预测错误的样本，0 和 0.005 的差距非常大，是 15 和 2 的差别。\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.clip.html\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-51c129c7d5bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sample_submission.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InceptionV3探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xception探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 3: 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "上面单独使用了Resnet50, InceptionV3, Exception模型进行尝试，成绩都不是太理想；\n",
    "下面会综合三个模型的特征来搭建一个全新的模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 4: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 5: 模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 6: 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 7: 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
